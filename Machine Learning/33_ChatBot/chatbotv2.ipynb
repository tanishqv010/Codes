{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02610c0d-66ec-4d7d-9ae5-536c52deb722",
   "metadata": {},
   "source": [
    "<h3>Importing the Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "252a9bc0-648e-4671-aeaa-b64c25641f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a39750-f039-4537-a665-00074066cbba",
   "metadata": {},
   "source": [
    "<h3>Data Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "734b6ab2-f79a-496d-a150-bcd220531f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(\"movie_lines.txt\", encoding = \"utf-8\", errors = \"ignore\").read().split(\"\\n\")\n",
    "conversations = open(\"movie_conversations.txt\", encoding = \"utf-8\", errors = \"ignore\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f76f9c-ffd2-4184-aeb2-e21467e8b98a",
   "metadata": {},
   "source": [
    "<h4>Creating a dictionary that maps each line and its id</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa45f3a3-e421-4640-a907-e35702353192",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(\" +++$+++ \")\n",
    "    if(len(_line) == 5):\n",
    "        id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61da929-ec40-495c-ae5c-faa897ed8c02",
   "metadata": {},
   "source": [
    "<h4>Creating a list of all of the conversations</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0baa1716-45be-447f-9739-b460fe7faf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_ids = []\n",
    "for conversation in conversations[:-1]:\n",
    "    _conversation = conversation.split(\" +++$+++ \")[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
    "    conversations_ids.append(_conversation.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90eb490-108d-4fdf-9e23-39375a84f8f8",
   "metadata": {},
   "source": [
    "<h4>Getting Separately the Questions and Answers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "593d8e16-3954-4d4e-bb86-c92f4b117ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "for conversation in conversations_ids:\n",
    "    for i in range(len(conversation) - 1):\n",
    "        questions.append(id2line[conversation[i]])\n",
    "        answers.append(id2line[conversation[i+1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c470e76-baa2-4e67-be8a-b80f6876025b",
   "metadata": {},
   "source": [
    "<h4>First Cleaning of the Texts</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3afa84dd-8966-4d0e-b8b9-a227fc94338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \"are\", text)\n",
    "    text = re.sub(r\"\\'d\", \"would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"[~()\\\"#/@;:<>{}+=-|.?,]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dff0b0-ab86-4e16-b75b-919e0c581645",
   "metadata": {},
   "source": [
    "<h4>Cleaning the Questions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08a58dd3-d30a-4d71-b1f8-a32bfb0b3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_questions = []\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b143c9-0e9b-4c35-abb1-9bd78891cfbf",
   "metadata": {},
   "source": [
    "<h4>Cleaning the Answers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c547ab03-4bfd-4336-a441-8db4ab610453",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_answers = []\n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ce34a-b3e9-4262-8d5c-7c659d3da33c",
   "metadata": {},
   "source": [
    "<h4>Creating a dictionary that maps each word to its number of occurances</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da4a4a88-3f67-403b-ae8e-a1c23a3bde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}\n",
    "for question in clean_questions:\n",
    "    for word in question.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for answer in clean_answers:\n",
    "    for word in answer.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0aa74e-384b-4028-ad3d-34a6a3f71074",
   "metadata": {},
   "source": [
    "<h4>Creating two Dictionaries that map the Questions Words and the Answers Words to a unique integer</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fa1d6c6-7587-4721-8551-0b6cd1e34a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20\n",
    "questionswords2int = {}\n",
    "word_number = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        questionswords2int[word] = word_number\n",
    "        word_number += 1\n",
    "answerswords2int = {}\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        answerswords2int[word] = word_number\n",
    "        word_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023f864-de93-40fb-935c-6cc98fa6ff17",
   "metadata": {},
   "source": [
    "<h4>Adding the Last Tokens to these two Dictionaries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b3a0e24-80ec-4b56-a14e-aa6c86de370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "for token in tokens:\n",
    "    questionswords2int[token] = len(questionswords2int) + 1\n",
    "for token in tokens:\n",
    "    answerswords2int[token] = len(answerswords2int) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ecb4c-3b18-49b0-a92c-b803f7d144c4",
   "metadata": {},
   "source": [
    "<h4>Creating the inverse dictionary of the answerswords2int dictionary</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c1810ce-3e16-4b40-970d-508e42bffe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answersints2word = {w_i: w for w, w_i in answerswords2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e9986-e222-4457-be5f-24848fd732a8",
   "metadata": {},
   "source": [
    "<h4>Adding the End Of String token to the end of every answer</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2016000d-b37a-4a6a-bfb1-43a29f6ac5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(clean_answers)):\n",
    "    clean_answers[i] += ' <EOS>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713c2a3-e35f-4642-b941-772effe53fd5",
   "metadata": {},
   "source": [
    "<h4>Translating all the questions and the answers into integers  and Replacing all the words that were filtered out </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb4ad058-506b-4a7f-b5c7-bea38f7bef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_int = []\n",
    "for question in clean_questions:\n",
    "    ints = []\n",
    "    for word in question.split():\n",
    "        if word not in questionswords2int:\n",
    "            ints.append(questionswords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(questionswords2int[word])\n",
    "    questions_to_int.append(ints)\n",
    "answers_to_int = []\n",
    "for answer in clean_answers:\n",
    "    ints = []\n",
    "    for word in answer.split():\n",
    "        if word not in answerswords2int:\n",
    "            ints.append(answerswords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(answerswords2int[word])\n",
    "    answers_to_int.append(ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa3a8c-edec-44b5-abbb-210c60705e7c",
   "metadata": {},
   "source": [
    "<h4>Sorting Questions and Answers by length of Questions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93eb8d7a-c535-4e0c-85b9-2b0501cfd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clean_questions = []\n",
    "sorted_clean_answers = []\n",
    "for length in range(1, 25 + 1):\n",
    "    for i in enumerate(questions_to_int):\n",
    "        if(len(i[1]) == length):\n",
    "            sorted_clean_questions.append(questions_to_int[i[0]])\n",
    "            sorted_clean_answers.append(answers_to_int[i[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5c33f-c68e-4595-aa32-ba3ab66f5b11",
   "metadata": {},
   "source": [
    "<h3>Building the Seq2seq Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6301921-9157-4f3b-875a-7b663b822d6f",
   "metadata": {},
   "source": [
    "<h4>Creating placehoders for the input and the targets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec0525c2-7577-42fa-9cbb-92a83f4ae7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    inputs = tf.compat.v1.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.compat.v1.placeholder(tf.int32, [None, None], name='target')\n",
    "    lr = tf.compat.v1.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.compat.v1.placeholder(tf.float32, name='keep_prob')\n",
    "    return inputs, targets, lr, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa05c53-1456-44a5-a40f-606c8546da78",
   "metadata": {},
   "source": [
    "<h4>Preprocessing the targets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eb4c97e-13b0-4ba7-8879-51a7dc6c76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_targets(targets, word2int, batch_size):\n",
    "    left_side = tf.fill([batch_size, 1], word2int['<SOS>'])\n",
    "    right_side = tf.strided_slice(targets, [0, 0], [batch_size, -1], [1, 1])\n",
    "    preprocessed_targets = tf.concat([left_side, right_side], 1)\n",
    "    return preprocessed_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772bc6f-9b50-4c63-b4f3-5fa165d31e96",
   "metadata": {},
   "source": [
    "<h4>Creating the Encoder RNN Layer</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac54485e-e9f0-4393-b149-35f607af3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_rnn_layer(rnn_inputs, rnn_size, num_layers, keep_prob, sequence_length):\n",
    "    lstm = tf.keras.layers.LSTMCell(rnn_size)\n",
    "    lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)\n",
    "    encoder_cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([lstm_dropout] * num_layers)\n",
    "    encoder_output, encoder_state = tf.compat.v1.nn.bidirectional_dynamic_rnn(cell_fw = encode_cell,\n",
    "                                                      cell_bw = encoder_cell,\n",
    "                                                      sequence_length = sequence_length,\n",
    "                                                      inputs = rnn_inputs,\n",
    "                                                      dtype = tf.float32)\n",
    "    return encoder_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60c827-2b3c-46a3-9edc-666c600a1908",
   "metadata": {},
   "source": [
    "<h4>Decoding the Training Set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f9dd741-b156-4918-b1bf-ef9ee230335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_training_set(encoder_state, decoder_cell, decoder_embedded_input, sequence_length, decoding_scope, output_function, keep_prob, batch_size):\n",
    "    attention_states = tf.zeroes([batch_size, 1, decoder_cell.output_size])\n",
    "    attention_keys, attention_values, attention_score_function, attention_construct_function = tf.contrib.seq2seq.prepare_attention(attention_states, attention_option = 'bahdanau', num_units = decoder_cell.output_size)\n",
    "    training_decoder_function = tf.contrib.seq2seq.attention_decoder_fn_train(encoder_state[0],\n",
    "                                                                              attention_keys,\n",
    "                                                                              attention_values,\n",
    "                                                                              attention_score_function,\n",
    "                                                                              attention_construct_function,\n",
    "                                                                             name = 'attn_dec_train')\n",
    "    decoder_output, decoder_final_state, decoder_final_context_state = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,\n",
    "                                                                                                             training_decoder_function,\n",
    "                                                                                                             decoder_embedded_inputs,\n",
    "                                                                                                             sequence_length,\n",
    "                                                                                                             scope = decoding_scope)\n",
    "    decoder_output_dropout = tf.nn.dropout(decoder_output, rate=1 - (keep_prob))\n",
    "    return output_function(decoder_output_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47513a5d-9c09-4904-a2c7-b2fd62d1f134",
   "metadata": {},
   "source": [
    "<h4>Decoding the Test / Validation Set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78336622-5a67-4ef2-bf5c-99fb9f818ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_test_set(encoder_state, decoder_cell, decoder_embeddings_matrix, sos_id, eos_id, maximum_length, num_words, sequence_length, decoding_scope, output_function, keep_prob, batch_size):\n",
    "    attention_states = tf.zeroes([batch_size, 1, decoder_cell.output_size])\n",
    "    attention_keys, attention_values, attention_score_function, attention_construct_function = tf.contrib.seq2seq.prepare_attention(attention_states, attention_option = 'bahdanau', num_units = decoder_cell.output_size)\n",
    "    test_decoder_function = tf.contrib.seq2seq.attention_decoder_fn_inference(output_function,\n",
    "                                                                                  encoder_state[0],\n",
    "                                                                                  attention_keys,\n",
    "                                                                                  attention_values,\n",
    "                                                                                  attention_score_function,\n",
    "                                                                                  attention_construct_function,\n",
    "                                                                                  decoder_embeddings_matrix,\n",
    "                                                                                  sos_id,\n",
    "                                                                                  eos_id,\n",
    "                                                                                  maximum_length,\n",
    "                                                                                  num_words,\n",
    "                                                                                  name = 'attn_dec_inf')\n",
    "    test_predictions, decoder_final_state, decoder_final_context_state = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,\n",
    "                                                                                                                test_decoder_function,\n",
    "                                                                                                                scope = decoding_scope)\n",
    "    return test_predictions\n",
    "\n",
    "\n",
    "\n",
    "def custom_lstm_cell(units, dropout_rate):\n",
    "    lstm_cell = tf.keras.layers.LSTMCell(units=units)\n",
    "    dropout_lstm_cell = tf.keras.layers.Dropout(rate=dropout_rate)(lstm_cell)\n",
    "    return dropout_lstm_cell\n",
    "\n",
    "def decoder_rnn(decoder_embedded_input, decoder_embeddings_matrix, encoder_state,\n",
    "                num_words, sequence_length, rnn_size, num_layers, keep_prob):\n",
    "    stacked_lstm_dropout = tf.keras.layers.StackedRNNCells([custom_lstm_cell(units=rnn_size, dropout_rate=1 - keep_prob) for _ in range(num_layers)])\n",
    "    rnn_layer = tf.keras.layers.RNN(cell=stacked_lstm_dropout, return_sequences=True, return_state=True)\n",
    "    initial_state = encoder_state\n",
    "    rnn_outputs, _ = rnn_layer(decoder_embedded_input, initial_state=initial_state)\n",
    "    output_layer = tf.keras.layers.Dense(units=num_words, activation='softmax')\n",
    "    logits = output_layer(rnn_outputs)\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bf868a-795b-48c1-baec-43487df127dc",
   "metadata": {},
   "source": [
    "<h4>Creating the Decoder RNN</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65154a87-31df-41d3-9dfa-8b5fca920dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_rnn(decoder_embedded_input, decoder_embeddings_matrix, encoder_state, num_words, sequence_length, rnn_size, num_layers, word2int, keep_prob, batch_size):\n",
    "    with tf.compat.v1.variable_scope('decoding') as decoding_scope:\n",
    "        lstm = tf.keras.layers.LSTMCell(rnn_size)\n",
    "        \n",
    "        \n",
    "        # lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)\n",
    "        \n",
    "        lstm_dropout = tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells([tf.keras.layers.LSTMCell(units=rnn_size)] * num_layers),\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=False,\n",
    "                                   dropout=1 - keep_prob)(inputs)\n",
    "\n",
    "\n",
    "        \n",
    "        decoder_cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([lstm_dropout] * num_layers)\n",
    "        weights = tf.compat.v1.truncated_normal_initializer(stddev = 0.1)\n",
    "        biases = tf.zeroes_initializer()\n",
    "        output_function = lambda x: tf.contrib.layers.fully_connected(x,\n",
    "                                                                     num_words,\n",
    "                                                                     activation_function = 'relu',\n",
    "                                                                     normallization = None,\n",
    "                                                                     scope = decoding_scope,\n",
    "                                                                     weights_initializers = weights,\n",
    "                                                                     biases_initializer = biases)\n",
    "        training_predictions = decode_training_set(encoder_state,\n",
    "                                                  decoder_cell,\n",
    "                                                  decoder_embedded_input,\n",
    "                                                  sequence_length,\n",
    "                                                  decoding_scope,\n",
    "                                                  output_function,\n",
    "                                                  keep_prob,\n",
    "                                                  batch_size)\n",
    "        decoding_scope.reuse_variables()\n",
    "        test_predictions = decode_test_set(encoder_state,\n",
    "                                          decoder_cell,\n",
    "                                          decoder_embedded_matrix,\n",
    "                                          word2int['<SOS>'],\n",
    "                                          word2int['<EOS>'],\n",
    "                                          sequence_length - 1,\n",
    "                                          num_words,\n",
    "                                          decoding_scope,\n",
    "                                          output_function,\n",
    "                                          keep_prob,\n",
    "                                          batch_size)\n",
    "        return training_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4caee-01a8-4b14-a1f4-7c70fefef7c0",
   "metadata": {},
   "source": [
    "<h4>Building the Seq2Seq Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5427e1a-1c85-404f-b7dc-4b3f0353f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_rnn(inputs, rnn_size, num_layers, keep_prob, sequence_length):\n",
    "    # Define the RNN cell (e.g., LSTM cell)\n",
    "    rnn_cell = tf.keras.layers.LSTMCell(units=rnn_size)\n",
    "    \n",
    "    # Create a multi-layer RNN\n",
    "    stacked_rnn = tf.keras.layers.StackedRNNCells([rnn_cell] * num_layers)\n",
    "    \n",
    "    # Initialize the RNN state\n",
    "    initial_state = stacked_rnn.get_initial_state(inputs=None, batch_size=tf.shape(inputs)[0], dtype=tf.float32)\n",
    "    \n",
    "    # Create an RNN layer\n",
    "    rnn_layer = tf.keras.layers.RNN(cell=stacked_rnn, return_sequences=True, return_state=True)\n",
    "    \n",
    "    # Run the RNN on the input sequences\n",
    "    rnn_outputs = rnn_layer(inputs, initial_state=initial_state)\n",
    "    \n",
    "    # Apply dropout to the RNN outputs\n",
    "    rnn_outputs_with_dropout = tf.keras.layers.Dropout(rate=1 - keep_prob)(rnn_outputs[0])\n",
    "    \n",
    "    return rnn_outputs_with_dropout, rnn_outputs[1]  # Return the dropout applied outputs and final state\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62ef9a52-bb0f-4819-ad0c-039b5dc3b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(inputs, targets, keep_prob, batch_size, sequence_length, answers_num_words, questions_num_words, encoder_embedding_size, decoder_embedding_size, rnn_size, num_layers, questionswords2int):\n",
    "    # encoder_embedded_input = tf.contrib.layers.embed_sequence(inputs,\n",
    "    #                                                           answers_num_words + 1,\n",
    "    #                                                           encoder_embedding_size,\n",
    "    #                                                           initializer = tf.compat.v1.random_uniform_initializer(0, 1))\n",
    "\n",
    "    \n",
    "    \n",
    "    encoder_embedded_input = tf.keras.layers.Embedding(answers_num_words + 1,\n",
    "                                                       encoder_embedding_size,\n",
    "                                                       embeddings_initializer = tf.random_uniform_initializer(0, 1))(inputs)\n",
    "    \n",
    "    _, encoder_state = encoder_rnn(encoder_embedded_input, rnn_size, num_layers, keep_prob, sequence_length)\n",
    "    \n",
    "    preprocessed_targets = preprocess_targets(targets, questionswords2int, batch_size)\n",
    "    decoder_embeddings_matrix = tf.Variable(tf.random.uniform([questions_num_words + 1, decoder_embedding_size], 0, 1))\n",
    "    decoder_embedded_input = tf.nn.embedding_lookup(decoder_embeddings_matrix, preprocessed_targets)\n",
    "    \n",
    "    training_predictions, test_predictions = decoder_rnn(decoder_embedded_input,\n",
    "                                                         decoder_embeddings_matrix,\n",
    "                                                         encoder_state,\n",
    "                                                         questions_num_words,\n",
    "                                                         sequence_length,\n",
    "                                                         rnn_size,\n",
    "                                                         num_layers,\n",
    "                                                         questionswords2int,\n",
    "                                                         keep_prob,\n",
    "                                                         batch_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return training_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765c89a-d127-4533-92f6-de94c699034b",
   "metadata": {},
   "source": [
    "<h3>Training the Seq2Seq Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e415d1-84b5-4ba9-afab-7058d39fc2b1",
   "metadata": {},
   "source": [
    "<h4>Setting the Hyperparameters</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "517ed2ba-8034-4bd2-b0f9-44484066f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "rnn_size = 512\n",
    "num_layers = 3\n",
    "encoding_embedding_size = 512\n",
    "decoding_embedding_size = 512\n",
    "learning_rate = 0.01\n",
    "learning_rate_decay = 0.9\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9a1be-110e-480c-b287-e9e9890a7bd9",
   "metadata": {},
   "source": [
    "<h4>Defining a Session</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed277587-fbb2-42b5-bc8c-889f37425ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "session = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b18652-326f-446c-9a17-b9f90fd6c672",
   "metadata": {},
   "source": [
    "<h4>Loading the Model Inputs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13b3556b-44bb-4bdb-9fb8-3f5021e5776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets, lr, keep_prob = model_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ce3b5-9fba-4af3-8b59-fd9f8a8d94ce",
   "metadata": {},
   "source": [
    "<h4>Setting the Sequence Length</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "692324b9-bb9a-415f-9783-f9ecfb2bb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = tf.compat.v1.placeholder_with_default(25, None, name = 'sequence_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f35408-4bea-4ec0-bd79-d9d666844b55",
   "metadata": {},
   "source": [
    "<h4>Getting the shapes of the input tensor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "666c6aa9-9427-437f-8ea9-95a4d61ac1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = tf.shape(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec1b15-ff24-4849-95ca-a9dde950fba6",
   "metadata": {},
   "source": [
    "<h4>Getting the Training and the Test Predictions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ff3ab08-bc86-4520-85eb-9112244793db",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'dropout')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_predictions, test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mseq2seq_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mkeep_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manswerswords2int\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquestionswords2int\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mencoding_embedding_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mdecoding_embedding_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mrnn_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mquestionswords2int\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[77], line 19\u001b[0m, in \u001b[0;36mseq2seq_model\u001b[1;34m(inputs, targets, keep_prob, batch_size, sequence_length, answers_num_words, questions_num_words, encoder_embedding_size, decoder_embedding_size, rnn_size, num_layers, questionswords2int)\u001b[0m\n\u001b[0;32m     16\u001b[0m decoder_embeddings_matrix \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform([questions_num_words \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, decoder_embedding_size], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     17\u001b[0m decoder_embedded_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39membedding_lookup(decoder_embeddings_matrix, preprocessed_targets)\n\u001b[1;32m---> 19\u001b[0m training_predictions, test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_embedded_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mdecoder_embeddings_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mencoder_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mquestions_num_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mrnn_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mquestionswords2int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mkeep_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m training_predictions, test_predictions\n",
      "Cell \u001b[1;32mIn[75], line 8\u001b[0m, in \u001b[0;36mdecoder_rnn\u001b[1;34m(decoder_embedded_input, decoder_embeddings_matrix, encoder_state, num_words, sequence_length, rnn_size, num_layers, word2int, keep_prob, batch_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m lstm \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTMCell(rnn_size)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m lstm_dropout \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStackedRNNCells\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTMCell\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrnn_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mreturn_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkeep_prob\u001b[49m\u001b[43m)\u001b[49m(inputs)\n\u001b[0;32m     15\u001b[0m decoder_cell \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrnn_cell\u001b[38;5;241m.\u001b[39mMultiRNNCell([lstm_dropout] \u001b[38;5;241m*\u001b[39m num_layers)\n\u001b[0;32m     16\u001b[0m weights \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtruncated_normal_initializer(stddev \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\base_rnn.py:271\u001b[0m, in \u001b[0;36mRNN.__init__\u001b[1;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, time_major, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    266\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    267\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    269\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell \u001b[38;5;241m=\u001b[39m cell\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_sequences \u001b[38;5;241m=\u001b[39m return_sequences\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_v1.py:151\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m allowed_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimplementation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m }\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m \u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Mutable properties\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\generic_utils.py:514\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_kwargs:\n\u001b[1;32m--> 514\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'dropout')"
     ]
    }
   ],
   "source": [
    "training_predictions, test_predictions = seq2seq_model(tf.reverse(inputs, [-1]),\n",
    "                                                      targets,\n",
    "                                                      keep_prob,\n",
    "                                                      batch_size,\n",
    "                                                      sequence_length,\n",
    "                                                      len(answerswords2int),\n",
    "                                                      len(questionswords2int),\n",
    "                                                      encoding_embedding_size,\n",
    "                                                      decoding_embedding_size,\n",
    "                                                      rnn_size,\n",
    "                                                      num_layers,\n",
    "                                                      questionswords2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97453af3-64ee-4b3d-8dce-c6cf8aea55de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
